@misc{mlx2023,
  title     = {{MLX}: An array framework for {Apple} silicon},
  author    = {Awni Hannun and Jagrit Digani and Angelos Katharopoulos and Ronan Collobert},
  year      = {2023},
  url       = {https://github.com/ml-explore/mlx},
  note      = {Apple Machine Learning Research},
}

@misc{llamacpp,
  title     = {llama.cpp: {LLM} inference in {C/C++}},
  author    = {Georgi Gerganov and contributors},
  year      = {2023},
  url       = {https://github.com/ggerganov/llama.cpp},
}

@misc{ggml2023,
  title     = {ggml: Tensor library for machine learning},
  author    = {Georgi Gerganov},
  year      = {2023},
  url       = {https://github.com/ggerganov/ggml},
}

@misc{safetensors,
  title     = {Safetensors: A simple, safe way to store and distribute tensors},
  author    = {{Hugging Face}},
  year      = {2023},
  url       = {https://github.com/huggingface/safetensors},
}

@inproceedings{kwon2023vllm,
  title     = {Efficient Memory Management for Large Language Model Serving with {PagedAttention}},
  author    = {Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph Gonzalez and Hao Zhang and Ion Stoica},
  booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles (SOSP)},
  year      = {2023},
}

@misc{tensorrtllm,
  title     = {{TensorRT-LLM}: A {TensorRT} Toolbox for Optimized Large Language Model Inference},
  author    = {{NVIDIA}},
  year      = {2023},
  url       = {https://github.com/NVIDIA/TensorRT-LLM},
}

@inproceedings{dao2022flashattention,
  title     = {{FlashAttention}: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author    = {Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher R{\'e}},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2022},
}

@misc{qwen3,
  title     = {Qwen3 Technical Report},
  author    = {{Qwen Team}},
  year      = {2025},
  url       = {https://qwenlm.github.io/blog/qwen3/},
}
